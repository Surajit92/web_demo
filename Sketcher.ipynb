{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sketcher.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Surajit92/web_demo/blob/master/Sketcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H3ATAdp_URp",
        "colab_type": "text"
      },
      "source": [
        "# Get the Class names "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlx6-LFL_jbi",
        "colab_type": "text"
      },
      "source": [
        "This file contains a subset of the quick draw classes. I choose around 100 classes from the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXv-xzU1sd88",
        "colab_type": "code",
        "outputId": "4f27ae27-c4d4-4edb-9728-2d1f11b28a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-20 10:17:44--  https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 760 [text/plain]\n",
            "Saving to: ‘mini_classes.txt’\n",
            "\n",
            "\rmini_classes.txt      0%[                    ]       0  --.-KB/s               \rmini_classes.txt    100%[===================>]     760  --.-KB/s    in 0s      \n",
            "\n",
            "2019-10-20 10:17:44 (84.5 MB/s) - ‘mini_classes.txt’ saved [760/760]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GL_TdMffD6-",
        "colab_type": "text"
      },
      "source": [
        "Read the classes names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP-OxOx5sy0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"mini_classes.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = f.readlines()\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTE6D3uxtMc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NDfBHVjACAt",
        "colab_type": "text"
      },
      "source": [
        "# Download the Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MC_PUS-fKjH",
        "colab_type": "text"
      },
      "source": [
        "Loop over the classes and download the currospondent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdSUnpL0u22Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22DPhL5FtWcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "def download():\n",
        "  \n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5jF6TXXu-Bu",
        "colab_type": "code",
        "outputId": "71bd1424-d1b8-428c-f736-6c3d8c081dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "download() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEdnbBVXAI-X",
        "colab_type": "text"
      },
      "source": [
        "# Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2FYrPgOKh6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o30ipBPAQ5Y",
        "colab_type": "text"
      },
      "source": [
        "# Load the Data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBq3GXEKAYuO",
        "colab_type": "text"
      },
      "source": [
        "Each class contains different number samples of arrays stored as .npy format. Since we have some memory limitations we only load 5000 images per class.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HEIgQNHYQnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 4000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6uUjN-WL2Y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhGEDS0SMgLK",
        "colab_type": "code",
        "outputId": "c133395c-3464-4762-a672-aeb5b7284f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "320000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNZmQvBWBBHE",
        "colab_type": "text"
      },
      "source": [
        "Show some random data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfpDaHRkyMQC",
        "colab_type": "code",
        "outputId": "dd65057c-8f09-41bf-be8f-5365b1937f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "airplane\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIvxAUIQfCIrwA0H9P7Le3bMRD0xvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8InHz5NBFrV",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess the Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2GHUq7D2r9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL6XAb4hBMSc",
        "colab_type": "text"
      },
      "source": [
        "# The Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYUVV2wf2z8H",
        "colab_type": "code",
        "outputId": "393132d3-be7b-4864-ebe3-155b8c0a783a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(100, activation='softmax')) \n",
        "# Train model\n",
        "adam = tf.train.AdamOptimizer()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 110,052\n",
            "Trainable params: 110,052\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YRSRkOyBP1P",
        "colab_type": "text"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OMEJ7kF3lsP",
        "colab_type": "code",
        "outputId": "f3928524-65be-4014-bd75-e1580467e7a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 288000 samples, validate on 32000 samples\n",
            "Epoch 1/5\n",
            "288000/288000 - 46s - loss: 1.9089 - top_k_categorical_accuracy: 0.7828 - val_loss: 1.3471 - val_top_k_categorical_accuracy: 0.8808\n",
            "Epoch 2/5\n",
            "288000/288000 - 46s - loss: 1.2267 - top_k_categorical_accuracy: 0.8945 - val_loss: 1.1678 - val_top_k_categorical_accuracy: 0.8989\n",
            "Epoch 3/5\n",
            "288000/288000 - 17s - loss: 1.0714 - top_k_categorical_accuracy: 0.9116 - val_loss: 1.0482 - val_top_k_categorical_accuracy: 0.9129\n",
            "Epoch 4/5\n",
            "288000/288000 - 34s - loss: 0.9846 - top_k_categorical_accuracy: 0.9208 - val_loss: 0.9791 - val_top_k_categorical_accuracy: 0.9207\n",
            "Epoch 5/5\n",
            "288000/288000 - 45s - loss: 0.9278 - top_k_categorical_accuracy: 0.9263 - val_loss: 0.9585 - val_top_k_categorical_accuracy: 0.9231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fba47eec780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2KztY7qEn9_",
        "colab_type": "text"
      },
      "source": [
        "# Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssaZczS7DxeA",
        "colab_type": "code",
        "outputId": "85ed23dd-3c45-42cb-8af3-f163c5a9335e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuarcy: 92.18%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xBM_w0VBbNr",
        "colab_type": "text"
      },
      "source": [
        "# Inference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH3JfoiYHdpk",
        "colab_type": "code",
        "outputId": "08e13b79-8a7a-4590-8984-b35e2f7f85d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "plt.imshow(img.squeeze()) \n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [class_names[x] for x in ind]\n",
        "print(latex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['eye', 'fan', 'wheel', 'pizza', 'grapes']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUZQfSNT/A/GpG0SKFcAqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPp5D82YBhM-",
        "colab_type": "text"
      },
      "source": [
        "# Store the classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoFI1msFYpCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfJ6dpaDBpRx",
        "colab_type": "text"
      },
      "source": [
        "# Install TensorFlowJS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJJDfp9mY9Xh",
        "colab_type": "code",
        "outputId": "797af7f2-c28d-4440-900f-75c968d04ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "!pip install tensorflowjs==1.2.6"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflowjs==1.2.6 in /usr/local/lib/python3.6/dist-packages (1.2.6)\n",
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs==1.2.6) (2.2.4)\n",
            "Requirement already satisfied: numpy==1.16.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs==1.2.6) (1.16.4)\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs==1.2.6) (1.11.0)\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs==1.2.6) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-hub==0.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs==1.2.6) (0.5.0)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs==1.2.6) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs==1.2.6) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs==1.2.6) (1.3.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs==1.2.6) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs==1.2.6) (3.13)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (0.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (0.33.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (0.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (3.7.1)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (1.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0->tensorflowjs==1.2.6) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->tensorflowjs==1.2.6) (0.15.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->tensorflowjs==1.2.6) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oBl0ZKVB00d",
        "colab_type": "text"
      },
      "source": [
        "# Save and Convert "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVICB3TbZGb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTWWlGdWZOvs",
        "colab_type": "code",
        "outputId": "14fd5f2a-3dc1-4f0c-8e72-50a0c5843732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKYxE2MEB6LV",
        "colab_type": "text"
      },
      "source": [
        "# Zip and Download "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "865-t79uaB63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp class_names.txt model/class_names.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLC-MzW8ZXTa",
        "colab_type": "code",
        "outputId": "2f6b3fc6-00c7-4f18-ee18-1c678fd7dccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!zip -r model.zip model "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model/ (stored 0%)\n",
            "  adding: model/group1-shard1of1.bin (deflated 7%)\n",
            "  adding: model/model.json (deflated 82%)\n",
            "  adding: model/class_names.txt (deflated 41%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vfPR03xZZeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}